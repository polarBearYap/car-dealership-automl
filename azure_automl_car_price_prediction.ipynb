{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe084c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.utilities import get_primary_metrics\n",
    "from azureml.interpret import ExplanationClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show cryptography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The current version of the Azure ML SDK is {azureml.core.VERSION}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a787fa",
   "metadata": {},
   "source": [
    "# Snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca7b9a",
   "metadata": {},
   "source": [
    "```python\n",
    "# Load the workspace specified by your parameters.\n",
    "# Configuration code to access the workspace from all notebooks using the Workspace.from_config() method\n",
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id, resource_group, workspace_name)\n",
    "    print(\"Found workspace {} at location {}\".format(ws.name, ws.location))\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d14284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'automl-car-price-prediction'\n",
    "\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Experiment Name'] = experiment.name\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedf14d2",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f99f13",
   "metadata": {},
   "source": [
    "```python\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_ds_name = ws.get_default_datastore().name\n",
    "curr_ds = Datastore.get(ws, default_ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e823a",
   "metadata": {},
   "source": [
    "```python\n",
    "# Upload files from local machine to the blob container the current datastore points to\n",
    "car_datasets_path = [\n",
    "    'output/car_train.csv',\n",
    "    'output/car_test.csv'\n",
    "]\n",
    "\n",
    "curr_ds.upload_files(car_datasets_path, target_path='./car_dataset', overwrite=False, show_progress=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce5027",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column_name = 'price'\n",
    "\n",
    "train_data = 'https://cardealershipa0525196035.blob.core.windows.net/azureml-blobstore-52e628b0-c309-4152-8e63-77d08607560b/car_dataset/car_train.csv'\n",
    "train_dataset = Dataset.Tabular.from_delimited_files(train_data)\n",
    "test_data = 'https://cardealershipa0525196035.blob.core.windows.net/azureml-blobstore-52e628b0-c309-4152-8e63-77d08607560b/car_dataset/car_test.csv'\n",
    "test_dataset = Dataset.Tabular.from_delimited_files(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03a9bb",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d0e33",
   "metadata": {},
   "source": [
    "## Choosing main metrics\n",
    "\n",
    "1) Difference between RMSE and MAE\n",
    "- In many circumstances it makes sense to give more weight to points further away from the mean--that is, being off by 10 is more than twice as bad as being off by 5. In such cases RMSE is a more appropriate measure of error.\n",
    "- If being off by ten is just twice as bad as being off by 5, then MAE is more appropriate.\n",
    "\n",
    "2) R2 is coefficient of determination, scaled between 0 and 1. R-squared is simply the fraction of response variance that is captured by the model. **It directly measures the goodness of fit in capturing the variance in training data.**\n",
    "\n",
    "- If R-squared = 1, means the model fits the data perfectly.\n",
    "- If R2=0.7, it says that with this model, we can explain 70% of what is going on in the real data, rest 30% canâ€™t be explained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac81e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    'training_data': train_dataset,\n",
    "    'label_column_name': label_column_name,\n",
    "    'task': 'regression',\n",
    "    'featurization': 'auto', # check will automl standardize the data? double-check\n",
    "    'primary_metric': 'normalized_root_mean_squared_error',\n",
    "    'validation_size': 0.08,\n",
    "    # https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.constants.supportedmodels.regression?view=azure-ml-py\n",
    "    'blocked_models': ['FastLinearRegressor', 'KNearestNeighborsRegressor', 'DecisionTreeRegressor'], \n",
    "    'model_explainablility': True,\n",
    "    'enable_dnn': False,\n",
    "    'path': './',\n",
    "    # 'compute_target': '', leave empty if run in local environment?\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(**automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c74058",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dea54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e595c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83748be",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e112c22d",
   "metadata": {},
   "source": [
    "## Retrieve the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa79464",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27f321",
   "metadata": {},
   "source": [
    "## Retrieve best model based on other metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e54f0",
   "metadata": {},
   "source": [
    "```python\n",
    "lookup_metric = \"root_mean_squared_error\"\n",
    "best_run, fitted_model = remote_run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(fitted_model)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_dataset.drop_columns(columns=[label_column_name]).to_pandas_dataframe()\n",
    "y_train_df = train_dataset.keep_columns(columns=[label_column_name], validate=True).to_pandas_dataframe()\n",
    "X_test_df = test_dataset.drop_columns(columns=[label_column_name]).to_pandas_dataframe()\n",
    "y_test_df = test_dataset.keep_columns(columns=[label_column_name], validate=True).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fef5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = fitted_model.predict(train_data)\n",
    "y_residual_train = y_train.values - y_pred_train\n",
    "\n",
    "y_pred_test = fitted_model.predict(test_data)\n",
    "y_residual_test = y_test.values - y_pred_tes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636abbc",
   "metadata": {},
   "source": [
    "## Plotting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set up a multi-plot chart.\n",
    "f, (a0, a1) = plt.subplots(1, 2, gridspec_kw = {'width_ratios':[1, 1], 'wspace':0, 'hspace': 0})\n",
    "f.suptitle('Regression Residual Values', fontsize = 18)\n",
    "f.set_figheight(6)\n",
    "f.set_figwidth(16)\n",
    "\n",
    "# Plot residual values of training set.\n",
    "a0.axis([0, 360, -100, 100])\n",
    "a0.plot(y_residual_train, 'bo', alpha = 0.5)\n",
    "a0.plot([-10,360],[0,0], 'r-', lw = 3)\n",
    "a0.text(16,170,'RMSE = {0:.2f}'.format(np.sqrt(mean_squared_error(y_train, y_pred_train))), fontsize = 12)\n",
    "a0.text(16,140,'R2 score = {0:.2f}'.format(r2_score(y_train, y_pred_train)),fontsize = 12)\n",
    "a0.set_xlabel('Training samples', fontsize = 12)\n",
    "a0.set_ylabel('Residual Values', fontsize = 12)\n",
    "\n",
    "# Plot residual values of test set.\n",
    "a1.axis([0, 90, -100, 100])\n",
    "a1.plot(y_residual_test, 'bo', alpha = 0.5)\n",
    "a1.plot([-10,360],[0,0], 'r-', lw = 3)\n",
    "a1.text(5,170,'RMSE = {0:.2f}'.format(np.sqrt(mean_squared_error(y_test, y_pred_test))), fontsize = 12)\n",
    "a1.text(5,140,'R2 score = {0:.2f}'.format(r2_score(y_test, y_pred_test)),fontsize = 12)\n",
    "a1.set_xlabel('Test samples', fontsize = 12)\n",
    "a1.set_yticklabels([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "test_pred = plt.scatter(y_test, y_pred_test, color='')\n",
    "test_test = plt.scatter(y_test, y_test, color='g')\n",
    "plt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164abd67",
   "metadata": {},
   "source": [
    "# Sources\n",
    "\n",
    "- https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/local-run-classification-credit-card-fraud/auto-ml-classification-credit-card-fraud-local.ipynb\n",
    "- https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/automated-machine-learning/regression/auto-ml-regression.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (azure_automl)",
   "language": "python",
   "name": "azure_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
